{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intended as a demo of my understanding of sequential data and not for market use. Crypto market is highly volatile and not suitable for trading.\n",
    "\n",
    "\n",
    "**The problem** ; given price and volume going back a certain number of lookback timesteps, and sampled every step, can we predict the price movement in delay_predict number of periods in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD\n",
      "LTC-USD\n",
      "BCH-USD\n",
      "ETH-USD\n",
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720       1.000000        1.000000       1.000000        1.000000   \n",
      "1528968780       0.998772        0.400740       0.999069        0.245334   \n",
      "1528968840       0.998772        0.182200       0.998345        0.022953   \n",
      "1528968900       0.998859        0.097711       0.997207        1.668453   \n",
      "1528968960       0.998862        0.193463       0.998552        0.054048   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720       1.000000        1.000000       1.000000        1.000000   \n",
      "1528968780       0.999127        0.041863       0.999979        0.324739   \n",
      "1528968840       0.999920        0.065156       0.999465        1.037494   \n",
      "1528968900       0.999012        0.062573       0.999979        2.973039   \n",
      "1528968960       0.999001        0.062145       0.999979        0.288377   \n",
      "\n",
      "            target  \n",
      "time                \n",
      "1528968720       0  \n",
      "1528968780       0  \n",
      "1528968840       1  \n",
      "1528968900       1  \n",
      "1528968960       0  \n",
      "0    58682\n",
      "1    39041\n",
      "Name: target, dtype: int64\n",
      "0    41992\n",
      "1    39041\n",
      "Name: target, dtype: int64\n",
      "Epoch 1/20\n",
      " - 93s - loss: 0.6916 - acc: 0.5238 - val_loss: 0.6912 - val_acc: 0.5283\n",
      "Epoch 2/20\n",
      " - 88s - loss: 0.6906 - acc: 0.5248 - val_loss: 0.6930 - val_acc: 0.5090\n",
      "Epoch 3/20\n",
      " - 87s - loss: 0.6905 - acc: 0.5260 - val_loss: 0.6920 - val_acc: 0.5261\n",
      "Epoch 4/20\n",
      " - 87s - loss: 0.6903 - acc: 0.5291 - val_loss: 0.6938 - val_acc: 0.5294\n",
      "Epoch 5/20\n",
      " - 86s - loss: 0.6900 - acc: 0.5296 - val_loss: 0.6952 - val_acc: 0.5288\n",
      "Epoch 6/20\n",
      " - 87s - loss: 0.6900 - acc: 0.5282 - val_loss: 0.6951 - val_acc: 0.5273\n",
      "Epoch 7/20\n",
      " - 87s - loss: 0.6900 - acc: 0.5282 - val_loss: 0.6962 - val_acc: 0.5282\n",
      "Epoch 8/20\n",
      " - 87s - loss: 0.6897 - acc: 0.5286 - val_loss: 0.6949 - val_acc: 0.5292\n",
      "Epoch 9/20\n",
      " - 87s - loss: 0.6897 - acc: 0.5300 - val_loss: 0.6967 - val_acc: 0.5314\n",
      "Epoch 10/20\n",
      " - 86s - loss: 0.6898 - acc: 0.5281 - val_loss: 0.6939 - val_acc: 0.5291\n",
      "Epoch 11/20\n",
      " - 87s - loss: 0.6896 - acc: 0.5305 - val_loss: 0.6953 - val_acc: 0.5309\n",
      "Epoch 12/20\n",
      " - 87s - loss: 0.6898 - acc: 0.5309 - val_loss: 0.6927 - val_acc: 0.5319\n",
      "Epoch 13/20\n",
      " - 86s - loss: 0.6896 - acc: 0.5314 - val_loss: 0.6926 - val_acc: 0.5313\n",
      "Epoch 14/20\n",
      " - 87s - loss: 0.6895 - acc: 0.5313 - val_loss: 0.6925 - val_acc: 0.5304\n",
      "Epoch 15/20\n",
      " - 100s - loss: 0.6893 - acc: 0.5328 - val_loss: 0.6921 - val_acc: 0.5321\n",
      "Epoch 16/20\n",
      " - 86s - loss: 0.6893 - acc: 0.5315 - val_loss: 0.6929 - val_acc: 0.5300\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ecb5cdbc1f0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m history = model.fit_generator(train_gen, steps_per_epoch=290, epochs=20,validation_data=val_gen, validation_steps=60,\n\u001b[1;32m--> 104\u001b[1;33m                               callbacks= [checkpoint], verbose=2)      \n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m     95\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.95\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \"\"\"\n\u001b[0;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 4119\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   4120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4033\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4034\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4152\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lookback = 30  # how long of a preceeding sequence to collect in minutes\n",
    "delay_period = 2  # how far into the future are we trying to predict in minutes?\n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "    \n",
    "main_df = pd.DataFrame() \n",
    "\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
    "for ratio in ratios:  \n",
    "    print(ratio)\n",
    "    dataset = f'{ratio}.csv'  \n",
    "    df = pd.read_csv(dataset, names=['time',  'close', 'volume'], usecols=[0,4,5], index_col='time')  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]] \n",
    "\n",
    "    if len(main_df)==0:  \n",
    "        main_df = df  \n",
    "    else:  \n",
    "        main_df = main_df.join(df) # join on index; time.\n",
    "\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "   \n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-delay_period) #shift cells up 2 periods\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1 #indicates a buy if future price is greater than current.\n",
    "    else:\n",
    "        return 0 # indicates a sell\n",
    "    \n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "main_df = main_df.drop(\"future\", 1) \n",
    "\n",
    "# normalizing\n",
    "for col in main_df.columns:  \n",
    "    if col != \"target\":  \n",
    "        main_df[col] = main_df[col]/(main_df[col].iloc[0])\n",
    "print(main_df.head()) \n",
    "\n",
    "\n",
    "print(main_df['target'].value_counts()) # 1 and 0 values are disproportionate in count.\n",
    "\n",
    "drop_number = (main_df.target.value_counts()).iloc[0]-(main_df.target.value_counts()).iloc[1]\n",
    "zero_class = []\n",
    "for i, row in enumerate(main_df.target):\n",
    "    if row == 0:\n",
    "        zero_class.append(i) #append indexes with zero class\n",
    "        \n",
    "zero_class_dropped = np.random.choice(zero_class, drop_number)\n",
    "main_df = main_df.reset_index().drop(zero_class_dropped).set_index('time')\n",
    "print(main_df.target.value_counts())\n",
    "\n",
    "# Because the samples in the dataset are highly redundant it would be computationally expensive\n",
    "# to pass every sample through the neural net. Instead, the generator generates samples with a step of 2.\n",
    "# Its also a great way to seperate the training data from validation and test sets.\n",
    "# The generator takes the input array of data and yields\n",
    "# batches of data of size 200 along with a target, zero or one, for each sequence. \n",
    "def generator(data, lookback, min_index, max_index, batch_size=200, step=2):\n",
    "    if max_index is None:\n",
    "        max_index = len(data)  - 1\n",
    "    i = min_index + lookback\n",
    "\n",
    "    while True:\n",
    "        if i + batch_size >= max_index:\n",
    "            i = min_index + lookback\n",
    "        rows = np.arange(i, min(i + batch_size, max_index))\n",
    "        i += len(rows)\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]-1)) #(samples, lookback steps, features)  \n",
    "        targets = np.zeros((len(rows),)) \n",
    "\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data.iloc[indices, 0:8]                           \n",
    "            targets[j] = data.iloc[rows[j]][8]        \n",
    "        yield samples, targets\n",
    "        \n",
    "train_gen = generator(main_df, lookback=lookback ,min_index=0, max_index=58030, step=2)\n",
    "val_gen = generator(main_df, lookback=lookback ,min_index=58001, max_index=70031, step=2)\n",
    "test_gen = generator(main_df, lookback=lookback  ,min_index=70002, max_index=81032, step=2)\n",
    "    \n",
    "# recommended to run on gpu, change lstm to cuDNNLSTM and remove the activation argument.\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(15, 8), activation='tanh', recurrent_dropout=0.2, return_sequences=True),\n",
    "    LSTM(128, activation='tanh', recurrent_dropout=0.2, return_sequences=True),\n",
    "    LSTM(128, activation='tanh', recurrent_dropout=0.2),\n",
    "\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')    \n",
    "    ])\n",
    "\n",
    "\n",
    "# Compile and run model\n",
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt ,metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint('weights.hdf5', monitor='val_acc', save_best_only=True)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=290, epochs=20,validation_data=val_gen, validation_steps=60,\n",
    "                              callbacks= [checkpoint], verbose=2)      \n",
    "\n",
    "\n",
    "# visualizing the epochs\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.xticks(range(1, len(acc) + 1, 2))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Out of sample test set evaluation\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(15, 8), activation='tanh', recurrent_dropout=0.2, return_sequences=True),\n",
    "    LSTM(128, activation='tanh', recurrent_dropout=0.2, return_sequences=True),\n",
    "    LSTM(128, activation='tanh', recurrent_dropout=0.2),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')    \n",
    "    ])\n",
    "\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt ,metrics=['accuracy'])\n",
    "\n",
    "test_eval = model.evaluate_generator(test_gen, steps=55)\n",
    "print(f'Out of sample test set accuracy is {test_eval[1]*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
